% $Author: ruben $
% $Date: 2010-05-09 22:31:50 $
% $Revision: 1.2 $

% For the FujabaDays 2006
\documentclass[submission,copyright,creativecommons]{eptcs}
\providecommand{\event}{TTC 2016} % Name of the event you are submitting to


\usepackage{graphicx,float,enumerate}
\usepackage{listings}
\usepackage{color}
\usepackage{wrapfig}

\graphicspath{{images/}}

\newcommand{\code}{\texttt}
\newcommand{\p}[1]{\textsf{#1}}


\setlength{\textwidth}{16.5cm}
\setlength{\oddsidemargin}{0cm}
\setlength{\evensidemargin}{0cm}
\setlength{\topmargin}{0cm}

\begin{document}

\definecolor{lightgray}{rgb}{.9,.9,.9}
\definecolor{darkgray}{rgb}{.4,.4,.4}
\definecolor{purple}{rgb}{0.5, 0, 0.33}
\definecolor{commentgreen}{rgb}{0.25,0.5,0.37} 
\definecolor{stringblue}{rgb}{0.16, 0, 1}
\definecolor{annotationgrey}{rgb}{0.39,0.39,0.39}


\lstdefinelanguage{Java}{
  keywords={typeof, try, long, void, new, true, false, catch, function, return,
  null, catch, switch, var, if, in, while, do, else, case, break, private, 
  protected,
  final, static, public, class, implements, extends, boolean, throws, throw,
  this, int, float, double}, 
  keywordstyle=\color{purple}\bfseries, ndkeywords={export}, 
  ndkeywordstyle=\color{darkgray}\bfseries,
  identifierstyle=\color{black},
  sensitive=true,
  comment=[l]{//},
  morecomment=[s]{/*}{*/},
  commentstyle=\color{commentgreen}\ttfamily,
  stringstyle=\color{stringblue}\ttfamily,
  morestring=[b]',
  morestring=[b]", 
  moredelim=[il][\textcolor{annotationgrey}]{$$},
  moredelim=[is][\textcolor{annotationgrey}]{\%\%}{\%\%}
}



\pagestyle{headings}

\title{The SDMLib solution to the Class Responsibility Assignment Case for TTC2016} 
\author{Christoph Eickhoff, Lennert Raesch, Albert Z{\"u}ndorf
\institute{
Kassel University, Software Engineering Research Group,\\
Wilhelmsh{\"o}her Allee 73, 34121 Kassel, Germany\\
\email{raesch|christoph|zuendorf@uni-kassel.de}
}}

\def\authorrunning{ Albert Z{\"u}ndorf}
\def\titlerunning{The SDMLib solution for TTC2016}

\maketitle

\begin{abstract}

This paper describes the SDMLib solution to the Class Responsibility Assignment Case 
for TTC2016. SDMLib provides reachability graph computation ala Groove. Thus, 
the simple idea was to provide rules for possible clustering operations and then use the
reachability graph computation to generate all possible clusterings. Then, we apply the
CRAIndex computation to each generated clustering and identify the best clustering. Of course,
this runs into scalability problems, very soon. Thus, we extended our reachability graph 
computation to do an A* based search space exploration. Therefore, we passed the CRAIndex 
computation as a metric to our reachability graph computation and in each step, we consider 
the set of not yet expanded graphs and choose the one, that has the best metric value for 
expansion. The paper reports about the results we achieved with this approach.  
   
  
\end{abstract}

\section{Introduction}
\label{sec:intro}

This paper describes the SDMLib solution to the Class Responsibility Assignment Case for TTC2016
\cite{ttc2016-case}. SDMLib provides reachability graph computation ala Groove 
\cite{rensink2003groove}. For a given start graph and a given set of rules, 
the reachability graph computation generates all graphs that may be derived from 
the start graph by applying all rules at all 
possible matches as often as possible in all possible orders. Each time a new 
graph is 
computed, we search through the set of already computed graphs for an already known 
isomorphic graph. As proposed by \cite{rensink2003groove}, SDMLib computes node and graph 
certificates which are then used as hash keys to access potentially isomorphic 
graphs efficiently. The node certificates then also help to do the actual 
isomorphism test. If a new 
graph has been generated, we create a so-called reachable state 
node and we connect the reachable state node of the predecessor graph with the reachable 
state node for the new graph via a rule application edge labeled with the name of 
the rule used. In addition, a root node of the graph is attached to the reachable state node. 
Altogether, the generated reachability graph has a top layer consisting of reachable 
state nodes connected via rule application edges and each reachable state node refers to 
the corresponding application graph via a \texttt{graphRoot} link. In SDMLib, this whole 
structure is again a graph, and graph rules may be applied to it in order to find e.g. 
reachable states with a maximal metric value for the attached application graph 
or to find states 
where all successor states have lower metric values or to find the shortest path leading to 
the best state. Actually, any graph related algorithm may be deployed.  

The Class Responsibility Assignment Case challenges the rule orchestration mechanisms 
provided by the different model transformation approaches. Thus, our solution uses the SDMLib 
reachability graph computation for rule orchestration. This is a very simple way to apply 
all rules in all possible ways and in addition we are able to investigate all intermediate 
results in order to identify which paths through the search space are the most interesting 
ones. The drawback of this approach is that it wastes a lot of runtime and memory space 
for copying the whole class model graph each time a rule is applied and for the search of 
already known isomorphic copies of the generated graphs. As shown in the case 
description, the number of possible clusterings grows with the Bell number, i.e. 
for larger examples a complete enumeration of all possible clustering is not possible in a 
meaningful time. As only a small fraction of the search space can be explored, it might be 
helpful to be able to investigate all intermediate states to identify the most promising spots 
for further expansion. Thus, we hope that the flexibility provided by the SDMLib reachability 
graphs to investigate different intermediate states pays off, in the end. 

As it is usually not possible to generate the whole reachability graph for a given example, 
our reachability graph computation may be restricted to a maximum number of reachable 
states to be considered. Next, we have extended our reachability graph computation with an A* 
like search space exploration that takes a metric as parameter and at each step chooses the 
state with the best metric value for expansion. We have developed two variants of this A* 
algorithm which will be discussed below. 

The next section introduces the rules we use to solve the Class Responsibility Assignment Case
and then Section~\ref{sec:expansion} shows the different search strategies we use in this 
example. Finally,~\ref{sec:results} shows our performance measurements. In the last section
we sum up our results. 
 
\section{The Model Transformation Rules}
\label{sec:rules}

Our feature clustering approach uses three SDMLib model transformation rules. In the 
preparation phase we use the rule shown in Figure~\ref{fig:RuleInitialClasses} to create 
one class for each feature in our class model. 

\begin{figure}[ht] \centering
	\includegraphics[width=\linewidth]{images/RuleAddInitialClasses.pdf}
 \caption{Rule adding initial classes}
 \label{fig:RuleInitialClasses}
\end{figure}

This rule starts by matching the pattern object \texttt{c1} to the 
\texttt{ClassModel} object passed as parameter. Then, \texttt{f2} is matched to a 
Feature object attached to this \texttt{ClassModel} object. The 
\texttt{\{allMatches\}} constraint causes the rule to be applied to all possible 
matches. Thus, for each \texttt{Feature} object in our current 
\texttt{ClassModel}, the \texttt {$<<$create$>>$ } sterotype on pattern object 
\texttt{c3} causes the creation of a new \texttt{Class} object. In addition 
the new \texttt{Class} object is attached to the \texttt{ClassModel} via a 
\texttt{classes} link and to the \texttt{Feature} object via an 
\texttt{encapsulates} link. Finally, the new \texttt{Class} object's \texttt{name} 
attribute gets assigned the concatenation of the prefix \texttt{"Class4"} 
and the \texttt{name} of the current \texttt{Feature}. Thus, after the 
execution of this rule, each feature has its own class containing just this 
feature. This class model is then used as starting point for the repetitive 
application of our clustering rules. 

We use two different clustering rules, one for clustering along data dependencies 
and one for clustering along functional dependencies. Figure~\ref{fig:MergeAttributeRule} 
shows the data dependency clustering rule \texttt{MergeDataDep}: 

\begin{figure}[ht] \centering
	\includegraphics[width=\linewidth]{images/RuleMergeDataDep.pdf}
 \caption{Merging Classes via Attribute Dependencies}
 \label{fig:MergeAttributeRule}
\end{figure}  

The matching of this rule starts with the \texttt{ClassModel} object which 
is bound to \texttt{c1} at rule invocation. Then we follow a \texttt{classes}
 edge to find a match for \texttt{c2}, i.e. a \texttt{Class} object in our 
\texttt{ClassModel}. Next, we follow an \texttt{encapsulates} edge to match 
a \texttt{Method} object \texttt{m4} contained in \texttt{c2}. The object 
matched by \texttt{m4} must have a \texttt{dataDependency} edge to an \texttt
{Attribute} object matched by the pattern object \texttt{a5}. This 
\texttt{Attribute} object in turn must be contained in a \texttt{Class} matched by 
\texttt{c6}. By default, SDMLib allows homomorphic matches, thus \texttt{c2} 
and \texttt{c6} would be allowed to match the same \texttt{Class} object. 
Via the \texttt{\{matchOtherThen c2\}} clause, we enforce isomorphic 
matching, i.e. \texttt{c2} and \texttt{c6} must match two different 
\texttt{Class} objects. Finally, the Class matched by \texttt{c6} must belong to our 
\texttt{ClassModel} \texttt{c1}. When such a match is found, the subpattern 
containing the \texttt{FeaturePO} pattern object \texttt{f7} is executed on 
all possible matches. Pattern object \texttt{f7} matches for all features 
contained in the \texttt{Class} matched by \texttt{c6}. (Note, \texttt{f7} 
exploits homomorphic matching and will also match the \texttt{Attribute} 
object already matched by \texttt{a5}.) For each \texttt{Feature} object, 
the \texttt{encapsulates} edge connecting it to the \texttt{Class} matched 
by \texttt{c6} is deleted and a new \texttt{isEncapsulatedBy} edge 
connecting it to the \texttt{Class} matched by \texttt{c2} is created. After 
transferring all features to the \texttt{Class} matched by \texttt{c2}, the 
\texttt{Class} matched by \texttt{c6} is destroyed. Thus, the rule shown in 
Figure~\ref{fig:MergeAttributeRule} merges two classes that are connected 
via a \texttt{dataDependency} into one class. 

Figure~\ref{fig:MergeMethodRule} shows our second clustering rule \texttt{MergeFuncDep}. 
It works similar to rule \texttt{MergeDataDep} but it applies to a pair of classes that
is connected via a \texttt{functionalDependency}. 

\begin{figure}[ht] \centering
	\includegraphics[width=\linewidth]{images/RuleMergeMethodDep.pdf}
 \caption{Merging Classes via Method Dependencies}
 \label{fig:MergeMethodRule}
\end{figure}

Our two clustering rules merge classes only if there is a dependency between them. 
This already utilizes application specific knowledge about our CRAIndex metric. Our 
search space expansion will start with classes containing only one feature each. Merging 
classes without a dependency between them is not going to improve the CRAIndex of 
the resulting class model. Merging classes has the potential to improve the CRAIndex only 
if the classes contain features that depend on each other. Thus, our clustering rules 
are already optimized for the optimization of the CRAIndex. Using a different metric would 
perhabs require a more general clustering strategy. As the metric is evaluated 
during the search space exploration, it would be easy to simply merge any two 
classes, as any graphs resulting from applying a non metric improving rule 
would immediately be dismissed anyways.


\section{The Search Space Expansion Mechanisms}
\label{sec:expansion}

 


\begin{lstlisting}[language=Java, numbers=left, captionpos=b, 
label={Activity.initVariables.java}, escapeinside={\%}{\%},
caption={General Reachability Graph Computation}
]
ReachabilityGraph::explore(depth) {
   todo = new ArrayList();
   todo.add(this.startState);
   states.put(certificate(this.startState), startState);
   while (! todo.isEmpty() && states.size() <= depth) {
      current = todo.get(0); todo.remove(0);
      for(Rule r : this.rules) {
         while (r.findMatch()) {
            newState = current.clone().apply(r);
            isoOldState = find(states, newState);
            if (isoOldState == null){
               states.put(certificate(newState), newState);
            	 addEdge(current, r, newState);
             	 todo.add(newState);
            } else {
               addEdge(current, r, isoOldState);
            }
         }
      }
   }
}

\end{lstlisting}

As seen in Listing \ref{Activity.initVariables.java} the only limiting factor 
is the depth passed to the explore function. In most scenarios the given rules 
are a lot more specific and can be applied for fewer matches througout a common 
graph. Thus, in most cases a complete reachability graph can in fact be 
generated in a justifiable amount of time and is most likely what a user 
expects. To adjust for a broader use and examples like the current challenge, 
we have implemented two additional exploration algorithms. It is therefor now 
possible to choose from the three different modes and still pass the depth of 
the expansion, offering great flexibility for search space exploration. The 
three modes are the following:

\subsection{Default mode aka full search space exploration}

The default mode will do a complete search space exploration when no depth 
constraint is given, working as described in Listing 
\ref{Activity.initVariables.java}. Limiting the depth will result in 	
breadth-first expansion of the reachability graph until the limit of graphs is 
reached.

\subsection{Metric-based "ignore decline" mode}

For both implemented modes, the metric passed to the explore function is 
evaluated for all graphs. The list of graphs to still be explored is also 
ordered based on the metric, thus graphs with a better metric are explored 
earlier on. However to different algorithms can be applied to how the search 
space is explored. The first mode, the metric-based ignore mode as depicted in 
Listing \ref{lst:ignore}, will expand 
the currently explored graph by applying all rules at all possible matches, but 
ignore, i.e. not add to the further to be explored graphs, all those graphs 
with a worse result for the given metric.

\begin{lstlisting}[language=Java, numbers=left, captionpos=b, 
label={lst:ignore}, escapeinside={\%}{\%},
caption={Metric based Reachability Graph Computation}
]
ReachabilityGraph::explore(depth, metric) {
	todo = new ArrayList();
	todo.add(this.startState);
	states.put(certificate(this.startState), startState);
	while (! todo.isEmpty() && states.size() <= depth) {
		Collections.sort(todo, metric);
		current = todo.get(0); todo.remove(0);
		for(Rule r : this.rules) {
			while (r.findMatch()) {
				newState = current.clone().apply(r);
				if(metric(newState) < bestMetric){
					continue;
				}else{
					bestMetric = metric(newState);
				}
				isoOldState = find(states, newState);
				if (isoOldState == null){
					states.put(certificate(newState), newState);
					addEdge(current, r, newState);
					todo.add(newState);
				} else {
				addEdge(current, r, isoOldState);
				}
			}
		}
	}
}

\end{lstlisting}

\subsection{Metric-based "promote improvement" mode}

The second mode promotes any improvements in the applied metric, thus stopping 
the current expansion step as soon as the metric yields a better result for a 
newly generated graph. No further rules are applied to the current graph and 
the discovered graph will now be explored as depicted in Listing 
\ref{lst:improve}. This algorithm very quickly returns 
local optimums of the reachability graph. In case it can not further enhance a 
local optimum it stores the state of expansion on earlier graphs and continues 
expanding them later on, so it will not only lead to the first local optimum 
but rather detect a few, depending on how many steps are necessary to reach 
them and limited by the depth constraint.

\begin{lstlisting}[language=Java, numbers=left, captionpos=b, 
label={lst:improve}, escapeinside={\%}{\%},
caption={Metric based depth first Reachability Graph Computation}
]
ReachabilityGraph::explore(depth, metric) {
	todo = new ArrayList();
	todo.add(this.startState);
	states.put(certificate(this.startState), startState);
	improve: while (! todo.isEmpty() && states.size() <= depth) {
		Collections.sort(todo, metric);
		current = todo.get(0); todo.remove(0);
		for(Rule r : this.rules) {
			while (r.findMatch()) {
				newState = current.clone().apply(r);
				if(metric(newState) < bestMetric){
					continue;
				}else{
				bestMetric = metric(newState);
			}
			isoOldState = find(states, newState);
			if (isoOldState == null){
				states.put(certificate(newState), newState);
				addEdge(current, r, newState);
				todo.add(newState);
				if(metric(newState) > bestMetric){
					bestMetric = metric(newState);
					continue improve;
				}
			} else {
			addEdge(current, r, isoOldState);
			}
		}
	}
}

\end{lstlisting}

\section{Performance Results}
\label{sec:results}



\section{Summary}
\label{sec:summary}

 

\bibliographystyle{abbrv}
\bibliography{fujaba}  

\end{document}

 